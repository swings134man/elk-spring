## ES - Query 활용


### 1. Paging (페이징)

- 매개변수를 지정하기만 하면 된다.
- 'from', 'size' 를 사용한다.
  - 기존 프로그래밍 산수 방식과 같음
    - 0 ~ n 개씩 카운팅

* from: 시작점
* size: 가져올 갯수

-> 예를들어 Result1~10 이 있을때, Result 4부터 3개의 데이터라면
---> from: 3, size: 3 으로 지정하면 된다.

```text
sample

curl -XGET '127.0.0.1:9200/movies/_search?size=2&from=2&pretty'

curl -XGET 127.0.0.1:9200/movies/_search
{
    "size": 2,
    "from": 2,
    "query": {
        "match": {
            "title": "star"
        }
    }
}

주의점: 일반적으로 모든곳에서 페이징에 대해서 주의할점과 같음
반환결과수에 상한선을 두거나, 제한을 두는 등등 -> 성능저하 방지
```

---

### 2. Sorting (정렬)

- 'sort' 를 사용한다.
- 일반적으로 "sort=" 뒤에 정렬하려는 field 를 지정하여 사용한다. (sort=year)
- "asc" 또는 "desc" 를 사용하여 오름차순 또는 내림차순을 지정할 수 있다.
- 

>
> ### 문제점
> Text Field 는 정렬에 제한이 있다. </br>
> Text Field 는 정렬을 위해 keyword 로 변경해야한다. </br>
> 혹은 정렬에 사용할 Field 생성 </br>
> 혹은 text 필드에 keyword 서브 필드를 추가하여 해결할 수 있다.
> #### 원인 </br>
> Text Field 는 analyzer 에 의해 분석되고, 여러 개의 토큰으로 나누어진다.(토큰화) </br>
> -> "Hello World" 는 ["Hello", "World"] 로 분리된다. </br>
> 이러한 분리로 인해서, 원본 Text 데이터가 유지되지 않고, 검색, 정렬기준이 불명확해진다. </br>
> 정렬은 필드의 전체 값을 기준으로 하기 때문이다.

```text
** 서브 필드 추가 **
- 전체 텍스트 검색에 사용할 수 있는 name 필드뿐만 아니라, 정렬, 분석되지않은 필드를 필요로 하는 작업에 
사용할 수 있는 title.raw 필드도 생성한것이다.

curl -XPUT 127.0.0.1:9200/movies/ -d'
{
  "mappings": {
    "properties": {
      "name": {
        "type": "text",
        "fields": {
          "keyword": {
            "type": "keyword"
          }
        }
      }
    }
  }
}'

curl -XPUT 127.0.0.1:9200/movies/ -d'
{
  "mappings": {
    "properties": {
      "name": {
        "type": "text",
        "fields": {
          "raw": {
            "type": "keyword"
          }
        }
      }
    }
  }
}'

서브 필드 추가 이후 

curl -XGET 127.0.0.1:9200/movies/_search?sort=title.raw&pretty 로 정렬 가능
```

### 3. Fuzzy Query

- 오타를 포함한 검색을 할때 사용한다.

```text
- Fuzzy Matches 의 기본 개념은 
'레벤쉬테인 편집 거리' 부터 이루어진다. 
- 레벤쉬테인 편집 거리는 두 문자열 사이의 차이를 측정하는 방법이다.
    - 일반적인 오자와, 오타를 정량화 할 수 있다.
    
아래의 3가지 단계를 거친다.
1. 대체(Substitutions): 문자열에서 문자를 대체 -> 실수로 잘못된 문자를 입력했을떄 잡아냄
    - Interstellar -> Intersteller 라면, 편집거리를 '1' 로 설정해두었다면
    매치 하게되고, 결과를 반환한다.
2. 삽입(Insertions): 문자열에 문자를 추가 -> 실수로 문자하나를 더 추가했을때
3. 삭제(Deletions): 문자열에서 문자를 제거 -> 실수로 문자하나를 뺐을때
```

```text
기본적인 사용 방법
-> fuzziness 의 값을 설정하여, 최대 몇개의 틀린 문자를 허용할지 설정한다.
curl -XGET 127.0.0.1:9200/movies/_search?pretty -d'
{
    "query": {
        "fuzzy": {
            "title": {
                "value": "intersteller",
                "fuzziness": 2
            }
        }
    }
}

- fuzziness: AUTO
-> 문자열 길이에 따라 Fuzzy 를 다르게 설정할 수 있다.
 왜냐면 문자의 일정 비율이 넘는 오타는 더이상 의미가 없어지기 때문이다. 
 
--> 이때 AUTO 를 사용하게 된다면 1,2개 문자열에 대해선 어떤 종류의 오타도 허용하지 않는다.
3-5 개문자열 == 1개의 오타 허용
```

### 4. 부분 매치(Partial Matching)
- 검색할 때 접두사나 또는 문자열의 일부분을 일치 시키는 방법

```text
- prefix 쿼리 : 제공한 접두사를 포함하는 문자열을 검색하는 방법
-> "201" 을 파라미터로 넘겼을 떄 2011, 2012, 2013 과 같은 문자열을 검색한다. 

"query": {
    "prefix": {
        "year": "201"
    }
}

--------------------
- wildcard 쿼리 : 와일드카드("*")를 사용하여 문자열을 검색하는 방법

"query": {
    "wildcard": {
        "year": "1*"
    }
}
-> 1로 시작하는 모든 결과를 반환한다.
--EX) 19*3 으로 한다면 -> 1953, 1963 과 같은 결과를 반환한다
--------------------
- regexp 쿼리 : 정규표현식을 사용하여 문자열을 검색하는 방법
일반적인 정규표현식을 사용하여 쿼리함
```

### 5. Search AS you Type (쿼리-타임)
- 사용자가 입력하는 즉시 검색결과를 보여주는 방법 -> 네이버, 구글과 같이 입력도중에 결과를 보여주는 방식

```text
1. Query-Time Search-as-you-type
- ngram 을 사용하여 검색어를 분리하여 검색한다.
- ngram 은 문자열을 n개의 문자로 분리하는 방법이다.
- match_phrase_prefix 구문을 사용하며, match_phrase 와 비슷하게 동작한다.(phrase 를 사용해도 된다)
- 단점은 index 기반 솔루션에 비해 리소스가 많이 사용된다

"query": {
    "match_phrase_prefix": {
        "title": {
            "query": "star trek",
            "slop": 10
        }
    }
}
----------------------------------

데이터가 'search-as-you-type' 유형으로 indexing, Mapping 되었을때
Es 는 원본 텍스트를 N-gram 으로 분리하여, 빠르게 부분매치 할 수 있도록
여러 하위 필드를 자동으로 생성한다. 
-> N-gram 은 sayt 타입으로 매핑된 경우에, 텍스트 분석 단계에서 생성된다.
-> 예를들어 Star Wars: Episode VII 가 있을때
2-그램: ["Star Wars", "Wars Episode", "Episode VII"] 등등으로 분리
3-그램: ["Star Wars Episode", "Wars Episode VII"] 등등으로 분리
index-prefix: ["S", "St", "Sta", "Star"]

즉 우리가 보는 자동완성은 사용자가 한글자씩 입력할떄마다 쿼리가 실행되는것.
----------------------------------
2. Search as you Type 설정

2-1 분석실행
curl --silent --request POST 'http://localhost:9200/movies/_analyze?pretty' --header 'Content-Type: application/json' --data-raw '{
  "tokenizer": "standard",
  "filter": [{"type: "edge_ngram", "min_gram": 1, "max_gram": 4}]
  "text": "Star"
}'

2-2 Mapping
curl --request PUT 'http://localhost:9200/autocomplete' --header 'Content-Type: application/json' --data-raw '{
  "mappings": {
    "properties": {
      "title": {
        "type": "search_as_you_type"
      },
      "genre": {
        "type": "search_as_you_type"
      }
    }
  }
}'

2-3 ReIndexing -> movies 에서 autocomplete 로 불러오기
curl --silent --request POST 'http://localhost:9200/_reindex?pretty' --header 'Content-Type: application/json' --data-raw '{
  "source": {
    "index": "movies"
  },
  "dest": {
    "index": "autocomplete"
  }
}' | grep "total\|created\|failures"

2-4. 
```

#### 5-1 N-grams
-
- ngram 은 문자열을 n개의 문자로 분리하는 방법이다.
- ngram 을 사용하여 검색어를 분리하여 검색한다.
- 아래의 Ngram 개념은 "Search As you Type" 에 적용할 수 있다. -> 입력값을 Ngram 으로 취급한다.

** edge_Ngram **
- 문자열의 시작부분에서 n개의 문자를 추출하는 방법
- 즉 주어진 용어의 앞부분에 대한 N-gram 을 계산한다.

```text
Ngram 이란? (개념) 

"star"

uni-gram: [s, t, a, r]
bi-gram: [st, ta, ar]
tri-gram: [sta, tar]
4-gram: [star]
-------------------------------------------------------------------------------------
* ES 에서 적용하는 방법(Indexing)
1. AutoComplete analyzer 를 사용한다. (자동완성(auto complete)이라고 부를, 맞춤형 분석기 생성)
-> edge-ngram 을 생성하는 자체 Custom Filter
curl -XPUT 12~/movies?pretty
{
    "settings": {
        "analysis": {
            "filter": {
                "autocomplete_filter": {
                    "type": "edge_gram", // edge_ngram 을 사용한다.
                    "min_gram": 1, // 최소 길이
                    "max_gram": 20 // 최대 길이(For Search-as-you-type)
                }
            },
            "analyzer": { // 새로운 분석기 설정(Custom)
                "autocomplete": {
                    "type": "custom",
                    "tokenizer": "standard", //표준 Tokenizer 사용
                    "filter": ["lowercase", "autocomplete_filter"] // 소문자필터, Ngram 이 포함된 자동완성 필터
                }
            }
        }
    }
}
-------------------------------------------------------------------------------------
Custom Filter 생성(설정) 후에는 Indexing 하기전에 Mapping 설정을 해야한다.
-> Mapping 설정을 통해 자동완성 분석기를 사용하도록 설정한다.

curl -XPUT 127.0.0.1:9200/movies/_mapping?pretty -d'
{
    "properties": {
        "title": {
            "type": "text",
            "analyzer": "autocomplete"
        }
    }
}

-------------------------------------------------------------------------------------
이후 Query 에서 확인해야 하는데. 
입력하는 모든것을 N-gram 으로 나누는것이 아니고
Index 에서 만든 N-gram 과 매치해야 한다.

curl -XGET 127.0.0.1:9200/movies/_search?pretty -d'
{
    "query": {
        "match": {
            "title": {
                "query": "sta",
                "analyzer": "standard" // standard 일땐 표준 분석, autocomplete 일땐 Ngram 분석기 사용
            }
        }
    }
}

-> 기존에 Index 를 생성할 때, N-Gram 으로 만들었기에 일반적인 match 쿼리 사용시
Uni-gram, bi-gram, tri-gram 등등을 사용하여 검색한다. -> 즉 s, t, a 모두 검색하기때문에 원하는 결과값이 안나올수가 있다.
그렇기에 정확하게 검색하려면 
위의 예제처럼 "analyzer": "standard" 를 사용하여 검색해야한다.(관련된 정확한 검색만함)
```



#### 5-2 Completion Suggesters 
- Search-as-you-type 의 또다른 방법 
- 자동완성의 완료 목록을 미리 업로드 하는 방법이다. 
- 최대한 효율적이고, 자동완성기능을 완벽하게 통제하고 싶을때 사용하는 방법이다.